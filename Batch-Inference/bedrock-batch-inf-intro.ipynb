{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8855ded-09a1-4c85-9dc4-91bef2efc1da",
   "metadata": {},
   "source": [
    "# Bedrock Batch Inference Introduction\n",
    "In this notebook we'll take a quick look at the [Bedrock Batch API](https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference.html) and take a look at how we can utilize it to solve asynchronous tasks such as summarization. In coming notebooks we'll dive into some more real-world use-cases where you can utilize this feature.\n",
    "\n",
    "\n",
    "### Setup\n",
    "We are working in a conda_python3 kernel in a ml.c5.xlarge SageMaker Classic Notebook Instance. You can also execute this in your own environment, note that you need permissions to read and write from S3 with your execution role as well as Bedrock access to work with the Batch API.\n",
    "\n",
    "### Additional Resources/Credits\n",
    "- [Official Bedrock Batch Blog](https://aws.amazon.com/blogs/machine-learning/automate-amazon-bedrock-batch-inference-building-a-scalable-and-efficient-pipeline/)\n",
    "- [Bedrock Batch Samples](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/introduction-to-bedrock/batch_api)\n",
    "- [Batch API Docs](https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0a917-508c-4cab-ba3a-32aae8d0eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3==1.35.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07309a70-e049-4e05-9109-a5a8439fd989",
   "metadata": {},
   "source": [
    "## Data Creation\n",
    "Here we can artifically generate a dataset with a dummy transcript that we'll use Claude 3 Haiku to summarize, funnily enough we use Haiku to generate the sample prompt as well. We then structure the payload in the format Claude expects: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-data.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dee2af-ab13-4bb0-bbab-b86ac63e5b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize Bedrock Runtime Client\n",
    "bedrock = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "# Dummy prompt\n",
    "prompt = \"Generate a realistic customer support call transcript about resolving a billing issue.\"\n",
    "\n",
    "# Function to generate dummy data\n",
    "def generate_data(input_prompt: str = prompt, model_id: str = \"anthropic.claude-3-haiku-20240307-v1:0\", \n",
    "                  anthropic_version: str = \"bedrock-2023-05-31\", max_tokens: int = 500,\n",
    "                  mime_type: str = \"application/json\") -> str:\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=json.dumps({\n",
    "            \"anthropic_version\": anthropic_version,\n",
    "            \"max_tokens\":  max_tokens,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }),\n",
    "        contentType=mime_type,\n",
    "        accept=mime_type\n",
    "    )\n",
    "\n",
    "    # Extract the transcript text\n",
    "    transcript_text = json.loads(response[\"body\"].read())[\"content\"][0][\"text\"]\n",
    "    return transcript_text\n",
    "\n",
    "mock_transcript_text = generate_data(prompt)\n",
    "print(mock_transcript_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d51d70-eba9-4039-a9b7-f0e91707e6b1",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f74de7-c531-4a4a-81b4-cc34739a057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation config for claude\n",
    "generation_config = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"system\": \"You are a helpful assistant. Please summarize the transcript provided.\",\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_p\": 0.99,\n",
    "    \"top_k\": 250\n",
    "}\n",
    "\n",
    "# Output file\n",
    "output_file = \"claude_haiku_batch_requests_summary.jsonl\"\n",
    "\n",
    "# Dummy file with 150 records\n",
    "with open(output_file, \"w\") as f:\n",
    "    for i in range(150):\n",
    "        record = {\n",
    "            \"recordId\": f\"REC{i:08d}\",\n",
    "            \"modelInput\": {\n",
    "                **generation_config,\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": f\"Summarize the following call transcript:\\n\\n{mock_transcript_text}\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "print(f\"Input data file created: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8180da04-abfb-4508-a634-1597b1e44525",
   "metadata": {},
   "source": [
    "### Upload Artifacts to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49e27a-b6e9-4c4d-80c3-df40357a5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "region = \"us-east-1\"\n",
    "file_key = f\"input_data/{output_file}\"\n",
    "\n",
    "# Create bucket and upload input data jsonlines file\n",
    "s3 = boto3.client(\"s3\", region_name=region)\n",
    "unique_suffix = str(uuid.uuid4())[:8]\n",
    "bucket_name = f\"bedrock-batch-{unique_suffix}\"\n",
    "\n",
    "s3.create_bucket(\n",
    "    Bucket=bucket_name)\n",
    "print(f\"Created bucket: {bucket_name}\")\n",
    "\n",
    "# Upload file\n",
    "s3.upload_file(Filename=output_file, Bucket=bucket_name, Key=file_key)\n",
    "input_s3_uri = f\"s3://{bucket_name}/{file_key}\"\n",
    "print(f\"Uploaded file to: {input_s3_uri}\")\n",
    "\n",
    "# Output folder for results\n",
    "output_prefix = \"output_results/\"\n",
    "s3.put_object(Bucket=bucket_name, Key=output_prefix)\n",
    "output_s3_uri = f\"s3://{bucket_name}/{output_prefix}\"\n",
    "print(f\"Created output folder: {output_s3_uri}\")\n",
    "\n",
    "print(f\"Input Data URI : {input_s3_uri}\")\n",
    "print(f\"Output Results URI: {output_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45baefc0-dbe3-496c-8683-9072a80a0689",
   "metadata": {},
   "source": [
    "## Create IAM Role\n",
    "Ensure we give read and write access to our S3 Bucket with input and output data locations: https://docs.aws.amazon.com/bedrock/latest/userguide/batch-iam-sr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879e43c-a1aa-4c66-82aa-c252f9938392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "region = 'us-east-1'  # Replace with your AWS region\n",
    "\n",
    "trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": \"bedrock.amazonaws.com\"},\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\"aws:SourceAccount\": account_id},\n",
    "                \"ArnEquals\": {\n",
    "                    \"aws:SourceArn\": f\"arn:aws:bedrock:{region}:{account_id}:model-invocation-job/*\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "role_name = f\"BedrockBatchInferenceRole-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "response = iam.create_role(\n",
    "    RoleName=role_name,\n",
    "    AssumeRolePolicyDocument=json.dumps(trust_policy),\n",
    "    Description=\"Service role for Amazon Bedrock batch inference\"\n",
    ")\n",
    "role_arn = response['Role']['Arn']\n",
    "print(f\"Created role: {role_arn}\")\n",
    "\n",
    "#Attach policy\n",
    "s3_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"S3Access\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{bucket_name}\",\n",
    "                f\"arn:aws:s3:::{bucket_name}/*\",\n",
    "                f\"arn:aws:s3:::{bucket_name}\",\n",
    "                f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "            ],\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:ResourceAccount\": account_id\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "iam.put_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyName=\"BedrockS3AccessPolicy\",\n",
    "    PolicyDocument=json.dumps(s3_policy)\n",
    ")\n",
    "print(\"Attached S3 access policy to the role.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcdfcd1-958c-4b89-9a92-1e30f9f36dd9",
   "metadata": {},
   "source": [
    "## Create Batch Job\n",
    "Boto3 API Call: https://docs.aws.amazon.com/bedrock/latest/APIReference/API_CreateModelInvocationJob.html#bedrock-CreateModelInvocationJob-request-inputDataConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ab6a1-d42b-40d9-bfcd-9b1229096c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDataConfig = {\n",
    "    \"s3InputDataConfig\": {\n",
    "        \"s3Uri\": input_s3_uri\n",
    "    }\n",
    "}\n",
    "\n",
    "outputDataConfig = {\n",
    "    \"s3OutputDataConfig\": {\n",
    "        \"s3Uri\": output_s3_uri\n",
    "    }\n",
    "}\n",
    "\n",
    "# client to create invocation job, different from runtime\n",
    "bedrock = boto3.client('bedrock', region_name = 'us-east-1')\n",
    "\n",
    "#model ID for the Batch Job\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "# start job\n",
    "response=bedrock.create_model_invocation_job(\n",
    "        roleArn=role_arn,\n",
    "        modelId=model_id,\n",
    "        jobName=f\"batch-claude-summarization-{str(__import__('uuid').uuid4())[:8]}\",\n",
    "        inputDataConfig=inputDataConfig,\n",
    "        outputDataConfig=outputDataConfig\n",
    "    )\n",
    "jobArn = response.get('jobArn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d48d9-f437-49ac-89bf-f91264227183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Snippet borrowed from: https://research-it.wharton.upenn.edu/programming/using-aws-bedrocks-batch-api/\n",
    "import time\n",
    "print(\"Monitoring batch job...\")\n",
    "while True:\n",
    "    job_status_response = bedrock.get_model_invocation_job(jobIdentifier=jobArn)\n",
    "    # Possible status: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock/client/get_model_invocation_job.html\n",
    "    status = job_status_response['status']\n",
    "    if status in ['InProgress', 'Initializing', 'Submitted', 'Validating', 'Scheduled']:\n",
    "        print(f\"Job {jobArn} is {status}. Waiting for completion...\")\n",
    "        time.sleep(100)\n",
    "    elif status == 'Completed':\n",
    "        print(f\"Job {jobArn} completed successfully.\")\n",
    "        break\n",
    "    elif status == 'Failed':\n",
    "        print(f\"Job {jobArn} failed.\")\n",
    "        raise RuntimeError(\"Job failed.\")\n",
    "    else:\n",
    "        print(f\"Job {jobArn} has unexpected status: {status}\")\n",
    "        time.sleep(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a427b-b86f-4139-b0fb-f215dc0495ff",
   "metadata": {},
   "source": [
    "## Parse Output Results\n",
    "You should see two files created: one manifest file with the cumulative job results and another out file with each individual output for the corresponding input. Ensure to adjust file path to reflect your output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e96808d-bce3-4cca-83a3-507a858248da",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = bedrock.list_model_invocation_jobs()['invocationJobSummaries']\n",
    "matching_job = next((job for job in jobs if job['jobArn'] == jobArn), None)\n",
    "output_results = matching_job['outputDataConfig']['s3OutputDataConfig']['s3Uri']\n",
    "output_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e608c4-fb5f-4304-8c80-27cab9815e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {output_results} ./results --recursive #creates a results folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24a6e5-4e1c-478c-b6d0-0d4d2c2fe928",
   "metadata": {},
   "source": [
    "### Cumulative Job Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89a72b-d5f8-4b43-9c80-5e31d134e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# replace with your file path\n",
    "file_path = 'results/ykfptibinz1x/manifest.json.out'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Overall metrics: {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb6ae87-fc30-4ae2-8764-7fed1f6fed7c",
   "metadata": {},
   "source": [
    "### Individual Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7e002-d195-49cd-b8be-20d189b78874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your file path\n",
    "file_path = 'results/ykfptibinz1x/claude_haiku_batch_requests_summary.jsonl.out'\n",
    "\n",
    "parsed_data = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "    \n",
    "        # Input text\n",
    "        input_text = \"\"\n",
    "        try:\n",
    "            input_text = data.get('modelInput', {}).get('messages', [])[0].get('content', [])[0].get('text', '')\n",
    "        except (IndexError, AttributeError):\n",
    "            pass\n",
    "    \n",
    "        # Output text\n",
    "        output_text = \"\"\n",
    "        try:\n",
    "            output_text = data.get('modelOutput', {}).get('content', [])[0].get('text', '')\n",
    "        except (IndexError, AttributeError):\n",
    "            pass\n",
    "    \n",
    "        # Record ID\n",
    "        record_id = data.get('recordId', '')\n",
    "    \n",
    "        # Store the extracted information\n",
    "        parsed_data.append({\n",
    "            'recordId': record_id,\n",
    "            'input_text': input_text,\n",
    "            'output_text': output_text\n",
    "        })\n",
    "\n",
    "for item in parsed_data:\n",
    "    print(f\"Record ID: {item['recordId']}\")\n",
    "    print(\"Input:\", item['input_text'])\n",
    "    print(\"Output:\", item['output_text'])\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
